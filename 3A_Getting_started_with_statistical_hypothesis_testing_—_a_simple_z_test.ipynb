{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3A Getting started with statistical hypothesis testing — a simple z-test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atlas-github/20190731StarMediaGroup/blob/master/3A_Getting_started_with_statistical_hypothesis_testing_%E2%80%94_a_simple_z_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DE2in9ys8dn",
        "colab_type": "text"
      },
      "source": [
        "_This is one of the 100+ free recipes of the [IPython Cookbook, Second Edition](https://ipython-books.github.io/), by [Cyrille Rossant](http://cyrille.rossant.net/), a guide to numerical computing and data science in the Jupyter Notebook. The ebook and printed book are available for purchase at [Packt Publishing](https://www.packtpub.com/big-data-and-business-intelligence/ipython-interactive-computing-and-visualization-cookbook-second-e)._\n",
        "\n",
        "+ ▶  _[Text on GitHub](https://github.com/ipython-books/cookbook-2nd) with a [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode)_\n",
        "+ ▶  _[Code on GitHub](https://github.com/ipython-books/cookbook-2nd-code) with a [MIT license](https://opensource.org/licenses/MIT)_\n",
        "+ ▶  _[Go to Chapter 7 : Statistical Data Analysis](https://ipython-books.github.io/chapter-7-statistical-data-analysis/)_\n",
        "+ ▶  _[Get the Jupyter notebook](https://github.com/ipython-books/cookbook-2nd-code)_\n",
        "\n",
        "__Statistical hypothesis testing__ allows us to make decisions in the presence of incomplete data. By definition, these decisions are uncertain. Statisticians have developed rigorous methods to evaluate this risk. Nevertheless, some subjectivity is always involved in the decision-making process. The theory is just a tool that helps us make decisions in an uncertain world.\n",
        "\n",
        "Here, we introduce the most basic ideas behind statistical hypothesis testing. We will follow an particularly simple example: coin tossing. More precisely, we will show how to perform a __z-test__, and we will briefly explain the mathematical ideas underlying it. This kind of method (also called the frequentist method), although widely used in science, is not without flaws and interpretation difficulties. We will show another approach based on Bayesian theory later in this chapter. It is very helpful to understand both approaches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXSNR3qTTBpL",
        "colab_type": "text"
      },
      "source": [
        "# A few simple examples first"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCuel1UdTHPS",
        "colab_type": "text"
      },
      "source": [
        "A principal at a certain school claims that the students in his school are above average intelligence. A random sample of thirty students IQ scores have a mean score of 112.5. Is there sufficient evidence to support the principal’s claim? The mean population IQ is 100 with a standard deviation of 15.\n",
        "\n",
        "[Source](https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/hypothesis-testing/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBxKiRfZTXHs",
        "colab_type": "text"
      },
      "source": [
        "##Step 1: State the null hypothesis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZfLLZDTT7ol",
        "colab_type": "text"
      },
      "source": [
        "$H_o:μ = 100$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCFkLW6mUPh7",
        "colab_type": "text"
      },
      "source": [
        "i.e. from the mean population IQ is 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "750LbYbCTbqM",
        "colab_type": "text"
      },
      "source": [
        "##Step 2: State the alternative hypothesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5xl-XwjUEis",
        "colab_type": "text"
      },
      "source": [
        "$H_1:μ > 100$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk9o7dBQUXa5",
        "colab_type": "text"
      },
      "source": [
        "i.e. the $>$ sign is from the principal's claim that the students in the school are of above average intelligence, and this is a one-tailed test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYBvVTc1TfHF",
        "colab_type": "text"
      },
      "source": [
        "##Step 3: Draw a picture to visualize the problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7t2yD_5VH81",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://www.statisticshowto.datasciencecentral.com/wp-content/uploads/2014/10/hypothesis-testing-example.jpg width=\"500\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tKKy4GPVM7m",
        "colab_type": "text"
      },
      "source": [
        "##Step 4: State the alpha (significance) level"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkCu7NkSV2nQ",
        "colab_type": "text"
      },
      "source": [
        "<img src=http://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_HypothesisTest-Means-Proportions/Standard%20Normal%20Distribution%20upper%20tail.png width=\"500\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84KyX0wxVTIQ",
        "colab_type": "text"
      },
      "source": [
        "##Step 5: Find the rejection region area from the alpha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLW8wpRqWhMP",
        "colab_type": "text"
      },
      "source": [
        "An area of $0.05$ is equal to a z-score of $1.645$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdZQEOHJW2xj",
        "colab_type": "text"
      },
      "source": [
        "##Step 6: Find the test statistic using this formula"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaY33mdIW-Jm",
        "colab_type": "text"
      },
      "source": [
        "$ z = \\frac {\\bar x - μ_o}{\\frac {σ}{\\sqrt n}} = \\frac {112.5 - 100}{\\frac {15}{\\sqrt {30}}}  = 4.56 $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek-nzXQ-X-rU",
        "colab_type": "text"
      },
      "source": [
        "$4.56 > 1.645$ so reject the null hypothesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n25OZAeYjfd",
        "colab_type": "text"
      },
      "source": [
        "### An alternative method would be to find the area instead of z-value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_9Yt69jYnx-",
        "colab_type": "text"
      },
      "source": [
        "$ P(\\bar X>112.5) = P(z > \\frac {112.5 - 100}{\\frac {15}{\\sqrt {30}}})$ = 0....."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCQg-wYFtA6e",
        "colab_type": "text"
      },
      "source": [
        "# How to do it..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjA1IvCbtC8f",
        "colab_type": "text"
      },
      "source": [
        "Many frequentist methods for hypothesis testing roughly involve the following steps:\n",
        "\n",
        "1.  Writing down the hypotheses, notably the __null hypothesis__, which is the opposite of the hypothesis we want to prove (with a certain degree of confidence). \n",
        "2.  Computing a __test statistic__, a mathematical formula depending on the test type, the model, the hypotheses, and the data. \n",
        "3.  Using the computed value to reject the hypothesis with a given level of uncertainty, or fail to conclude (and, consequently, accept the hypothesis until future studies reject it).\n",
        "\n",
        "For example, to test the efficacy of a new drug, doctors may consider, as a null hypothesis, that the drug has no statistically significant effect on a group of patients compared to a control group of patients who do not take the drug. If studies reject the null hypothesis, it is an argument in favor of the efficacy of the drug (but it is not a definite proof).\n",
        "\n",
        "Here, we flip a coin $n$ times and we observe $h$ heads. We want to know whether the coin is fair (null hypothesis). This example is particularly simple yet quite useful for pedagogical purposes. Besides, it is the basis of many more complex methods.\n",
        "\n",
        "We denote the Bernoulli distribution by $B(q)$ with the unknown parameter $q$. You can refer to https://en.wikipedia.org/wiki/Bernoulli_distribution for more information.\n",
        "\n",
        "A Bernoulli variable is:\n",
        "\n",
        "+ 0 (tail) with probability $1−q$\n",
        "+ 1 (head) with probability $q$\n",
        "\n",
        "Here are the steps required to conduct a simple statistical z-test:\n",
        "\n",
        "1. Let's suppose that after $n=100$ flips, we get $h=61$ heads. We choose a significance level of 0.05: is the coin fair or not? Our null hypothesis is: the coin is fair ($q=1/2$). We set these variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxKbjjIgskHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy.stats as st\n",
        "import scipy.special as sp\n",
        "\n",
        "n = 100  # number of coin flips\n",
        "h = 61  # number of heads\n",
        "q = .5  # null-hypothesis of fair coin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1QCRxcotHoY",
        "colab_type": "text"
      },
      "source": [
        "2. Let's compute the __z-score__, which is defined by the following formula (__xbar__ is the estimated average of the distribution). We will explain this formula in the next section, How it works..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GP1KnhotFbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xbar = float(h) / n\n",
        "z = (xbar - q) / np.sqrt((xbar * (1 - xbar)) / n)\n",
        "z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20yPGFfltL20",
        "colab_type": "text"
      },
      "source": [
        "3. Now, from the z-score, we can compute the p-value as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6N3XNSMtJdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pval = 2 * (1 - st.norm.cdf(z))\n",
        "pval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycOTz3FCJSUc",
        "colab_type": "text"
      },
      "source": [
        "#Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wj4w4UeJYHW",
        "colab_type": "text"
      },
      "source": [
        "Use the [statmodels.stats.proportion.proportions_ztest](https://www.statsmodels.org/devel/generated/statsmodels.stats.proportion.proportions_ztest.html) library to quickly solve the above problem. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DVJTv91KKi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "###INSERT CODE HERE\n",
        "\n",
        "print(\"z value\", zstat)\n",
        "print(\"p-values\", pvalue)\n",
        "\n",
        "if pvalue < 0.05:\n",
        "  print(\"Reject null hypothesis.\")\n",
        "else:\n",
        "  print(\"Accept null hypothesis.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJphYg2xtQY2",
        "colab_type": "text"
      },
      "source": [
        "# How it works..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eWVaw-_tRis",
        "colab_type": "text"
      },
      "source": [
        "The coin tossing experiment is modeled as a sequence of $n$ independent random variables $x_{i}∈{0,1}$ following the Bernoulli distribution $B(q)$. Each $x_{i}$ represents one coin flip. After our experiment, we get actual values (samples) for these variables. A different notation is sometimes used to distinguish between the random variables (probabilistic objects) and the actual values (samples).\n",
        "\n",
        "The following formula gives the __sample mean__ (proportion of heads here):\n",
        "\n",
        "$$\\bar x = \\frac{1}{n} \\sum_{i}x_{i}$$\n",
        "\n",
        "Knowing the expectancy $μ=q$ and variance $σ^2=q(1−q)$ of the distribution $B(q)$, we compute:\n",
        "\n",
        "$$E[\\bar x] = μ = q$$\n",
        "\n",
        "$$var(\\bar x) = \\frac {σ^2}{n}= \\frac{q(1−q)}{n}$$\n",
        "\n",
        "The z-test is the normalized version of $\\bar x$ (we remove its mean, and divide by the standard deviation, thus we get a variable with mean 0 and standard deviation 1):\n",
        "\n",
        "$$z = \\frac {\\bar x −E[\\bar x]}{std(\\bar x)} = (\\bar x − q) \\sqrt{\\frac {n}{q(1−q)}}$$\n",
        "\n",
        "Under the null hypothesis, what is the probability of obtaining a z-test higher (in absolute value) than some quantity $z_0$? This probability is called the (two-sided) p-value. According to the central limit theorem, the z-test approximately follows a standard Gaussian distribution $N(0,1)$ for large $n$, so we get:\n",
        "\n",
        "$$p=P[|z|>z_{0}]=2P[z>z_{0}]≃2(1−Φ(z_{0}))$$\n",
        "\n",
        "The following diagram illustrates the z-score and the p-value:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKrc0jPXts5u",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://ipython-books.github.io/pages/chapter07_stats/02_z_test_files/gaussian.png width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBGMbhx3twSn",
        "colab_type": "text"
      },
      "source": [
        "In this formula, $Φ$ is the __cumulative distribution__ function of a standard normal distribution. In SciPy, we can get it with __scipy.stats.norm.cdf__. So, given the z-test computed from the data, we compute the p-value: the probability of observing a z-test more extreme than the observed test, under the null hypothesis.\n",
        "\n",
        "If the p-value is less than five percent (a frequently-chosen significance level, for arbitrary and historical reasons), we conclude that either:\n",
        "\n",
        "The null hypothesis is false, thus we conclude that the coin is unfair.\n",
        "The null hypothesis is true, and it's just bad luck if we obtained these values. We cannot make a conclusion.\n",
        "We cannot disambiguate between these two options in this framework, but typically the first option is chosen. We hit the limits of frequentist statistics, although there are ways to mitigate this problem (for example, by conducting several independent studies and looking at all of their conclusions)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G3fGP11tyOg",
        "colab_type": "text"
      },
      "source": [
        "# There's more..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFfoMoZMt0P_",
        "colab_type": "text"
      },
      "source": [
        "There are many statistical tests that follow this pattern. Reviewing all those tests is largely beyond the scope of this book, but you can take a look at the reference at https://en.wikipedia.org/wiki/Statistical_hypothesis_testing.\n",
        "\n",
        "As a p-value is not easy to interpret, it can lead to wrong conclusions, even in peer-reviewed scientific publications. For an in-depth treatment of the subject, see http://www.refsmmat.com/statistics/.\n",
        "\n",
        "More statistical tests:\n",
        "\n",
        "|Type of test | Use|\n",
        "|--|--|\n",
        "|**Correlation: looks for statistical relationships between variables**|\n",
        "| [Correlation](https://en.wikipedia.org/wiki/Correlation_coefficient) | Looks for an association between variables|\n",
        "| [Pearson correlation](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) | Tests for strengths of the association between two continuous variables|\n",
        "| [Spearman correlation](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient) | Tests for the strength of the association between two ordinal variables (does not rely on the assumption of normally distributed data)|\n",
        "| [Chi-square](https://en.wikipedia.org/wiki/Chi-squared_test) | Tests for the strength of the association between two categorical variables|\n",
        "|**Comparison of Means: look for difference between the means of variables**|\n",
        "| [Paired T-test](https://en.wikipedia.org/wiki/Student%27s_t-test) | Tests for the difference between two related variables|\n",
        "| [Independent T-test](https://en.wikipedia.org/wiki/Student%27s_t-test#Independent_(unpaired)_samples) | Tests for the difference between two independent variables |\n",
        "| [ANOVA](https://en.wikipedia.org/wiki/Analysis_of_variance) | Tests the difference between group means **after** any other variance in the outcome variable is accounted for |\n",
        "|**Regression: assess if change in one variable predicts change in another variable**|\n",
        "| [Simple regression](https://en.wikipedia.org/wiki/Simple_linear_regression) | Tests how change in the predictor variable predicts the level of change in the outcome variable |\n",
        "| [Multiple regression](https://en.wikipedia.org/wiki/Polynomial_regression) | Tests how change in the combination of two or more predictor variables predict the level of change in the outcome variable |\n",
        "|**Non-parametric: used when the data does not meet assumptions required for parametric tests**|\n",
        "| [Wilcoxon rank-sum test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test) | Tests for the difference between two independent variables—takes into account magnitude and direction of difference|\n",
        "| [Wilcoxon sign-rank test](https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test) | Tests for the difference between two related variables—takes into account the magnitude and direction of difference |\n",
        "| [Sign test](https://en.wikipedia.org/wiki/Sign_test) | Tests if two related variables are different—ignores the magnitude of change, only takes into account direction |"
      ]
    }
  ]
}