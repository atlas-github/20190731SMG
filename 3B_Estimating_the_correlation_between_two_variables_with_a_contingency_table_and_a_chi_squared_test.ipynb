{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3B Estimating the correlation between two variables with a contingency table and a chi-squared test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atlas-github/20190731SMG/blob/master/3B_Estimating_the_correlation_between_two_variables_with_a_contingency_table_and_a_chi_squared_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Urs9kM2SvFk5",
        "colab_type": "text"
      },
      "source": [
        "_This is one of the 100+ free recipes of the [IPython Cookbook, Second Edition](https://ipython-books.github.io/), by [Cyrille Rossant](http://cyrille.rossant.net/), a guide to numerical computing and data science in the Jupyter Notebook. The ebook and printed book are available for purchase at [Packt Publishing](https://www.packtpub.com/big-data-and-business-intelligence/ipython-interactive-computing-and-visualization-cookbook-second-e)._\n",
        "\n",
        "+ ▶  _[Text on GitHub](https://github.com/ipython-books/cookbook-2nd) with a [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode)_\n",
        "+ ▶  _[Code on GitHub](https://github.com/ipython-books/cookbook-2nd-code) with a [MIT license](https://opensource.org/licenses/MIT)_\n",
        "+ ▶  _[Go to Chapter 7 : Statistical Data Analysis](https://ipython-books.github.io/chapter-7-statistical-data-analysis/)_\n",
        "+ ▶  _[Get the Jupyter notebook](https://github.com/ipython-books/cookbook-2nd-code)_\n",
        "\n",
        "Whereas univariate methods deal with single-variable observations, multivariate methods consider observations with several features. Multivariate datasets allow the study of _relations_ between variables, more particularly their correlation, or lack thereof (that is, independence).\n",
        "\n",
        "In this recipe, we will take a look at the same tennis dataset as in the first recipe of this chapter. Following a frequentist approach, we will estimate the correlation between the number of aces and the proportion of points won by a tennis player."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3eyHzECvJKv",
        "colab_type": "text"
      },
      "source": [
        "# How to do it..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq-goSKKvSuH",
        "colab_type": "text"
      },
      "source": [
        "1. Let's import NumPy, pandas, SciPy.stats, and matplotlib:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5PLmPk9u2k9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as st\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQdE13envVyg",
        "colab_type": "text"
      },
      "source": [
        "2. We download and load the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJz-cS6gvUaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "player = 'Roger Federer'\n",
        "df = pd.read_csv('https://github.com/ipython-books/'\n",
        "                 'cookbook-2nd-data/blob/master/'\n",
        "                 'federer.csv?raw=true',\n",
        "                 parse_dates=['start date'],\n",
        "                 dayfirst=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4yRei3wvZir",
        "colab_type": "text"
      },
      "source": [
        "3. Each row corresponds to a match, and the 70 columns contain many player characteristics during that match:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwK2D1-ZvXjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"Number of columns: {len(df.columns)}\")\n",
        "df[df.columns[:4]].tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3fIn1a4vdTA",
        "colab_type": "text"
      },
      "source": [
        "4. Here, we only look at the proportion of points won, and the (relative) number of aces:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6b0aW_gvbGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "npoints = df['player1 total points total']\n",
        "points = df['player1 total points won'] / npoints\n",
        "aces = df['player1 aces'] / npoints\n",
        "fig, ax = plt.subplots(1, 1)\n",
        "ax.plot(points, aces, '.')\n",
        "ax.set_xlabel('% of points won')\n",
        "ax.set_ylabel('% of aces')\n",
        "ax.set_xlim(0., 1.)\n",
        "ax.set_ylim(0.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUV4Ytigvg7J",
        "colab_type": "text"
      },
      "source": [
        "If the two variables were independent, we would not see any trend in the cloud of points. On this plot, it is a bit hard to tell. Let's use pandas to compute a coefficient correlation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPwpxZMxvkEC",
        "colab_type": "text"
      },
      "source": [
        "5. For simplicity, we create a new __DataFrame__ object with only these fields. We also remove the rows where one field is missing (using __dropna()__):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dipe6SU8vez8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_bis = pd.DataFrame({'points': points,\n",
        "                       'aces': aces}).dropna()\n",
        "df_bis.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00estcxuvnoy",
        "colab_type": "text"
      },
      "source": [
        "6. Let's compute the Pearson's correlation coefficient between the relative number of aces in the match, and the number of points won:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As69xGQMviak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_bis.corr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "radx9CfmvshA",
        "colab_type": "text"
      },
      "source": [
        "A correlation of ~0.26 seems to indicate a positive correlation between our two variables. In other words, the more aces in a match, the more points the player wins (which is not very surprising!)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PHqQ_R8vuuQ",
        "colab_type": "text"
      },
      "source": [
        "7. Now, to determine if there is a statistically significant correlation between the variables, we use a __chi-squared test__ of the independence of variables in a __contingency table__. \n",
        "8.  First, we binarize our variables. Here, the value corresponding to the number of aces is __True__ if the player is serving more aces than usual in a match, and __False__ otherwise:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-GmVOzQvp6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_bis['result'] = (df_bis['points'] >\n",
        "                    df_bis['points'].median())\n",
        "df_bis['manyaces'] = (df_bis['aces'] >\n",
        "                      df_bis['aces'].median())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TAOk4SPvyk8",
        "colab_type": "text"
      },
      "source": [
        "9. Then, we create a contingency table, with the frequencies of all four possibilities (True and True, True and False, and so on):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcOk7HIBvxAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.crosstab(df_bis['result'], df_bis['manyaces'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFHRaYp_v2cx",
        "colab_type": "text"
      },
      "source": [
        "10. Finally, we compute the chi-squared test statistic and the associated p-value. The null hypothesis is the independence between the variables. SciPy implements this test in __scipy.stats.chi2_contingency()__, which returns several objects. We're interested in the second result, which is the p-value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fveR65HBv00Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st.chi2_contingency(_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K6oQ-4cv4bR",
        "colab_type": "text"
      },
      "source": [
        "The p-value is much lower than 0.05, so we reject the null hypothesis and conclude that there is a statistically significant correlation between the proportion of aces and the proportion of points won in a match in this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j3jSQShv7Ro",
        "colab_type": "text"
      },
      "source": [
        "Correlation does not imply causation. Here, it is likely that external factors influence both variables. See https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k5IXUUlv-sy",
        "colab_type": "text"
      },
      "source": [
        "# How it works..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5Y7oeexwAVO",
        "colab_type": "text"
      },
      "source": [
        "We give here a few details about the statistical concepts used in this recipe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV6wmlIMwC4J",
        "colab_type": "text"
      },
      "source": [
        "## Pearson's correlation coefficient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsNav2wFwFh_",
        "colab_type": "text"
      },
      "source": [
        "Pearson's correlation coefficient measures the linear correlation between two random variables, $X$ and $Y$. It is a normalized version of the covariance:\n",
        "\n",
        "$$ρ=\\frac{cov(X,Y)}{\\sqrt {var(X)var(Y)}} = \\frac{E((X−E(X))(Y−E(Y)))}{\\sqrt {var(X)var(Y)}}$$\n",
        "\n",
        "It can be estimated by substituting, in this formula, the expectancy with the sample mean, and the variance with the sample variance. More details about its inference can be found at https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E577IUMawIXX",
        "colab_type": "text"
      },
      "source": [
        "## Contingency table and chi-squared test "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eW20rrBwKoV",
        "colab_type": "text"
      },
      "source": [
        "The contingency table contains the frequencies $O_{ij}$ of all combinations of outcomes, when there are multiple random variables that can take a finite number of values. Under the null hypothesis of independence, we can compute the _expected frequencies_ $E_{ij}$, based on the marginal sums (sums in each row). The chi-squared statistic, by definition, is:\n",
        "\n",
        "$$χ=∑_{i,j} \\frac{(O_{ij}−E_{ij})^2}{E_{ij}}$$\n",
        "\n",
        "When there are sufficiently many observations, this variable approximately follows a chi-squared distribution (the distribution of the sum of normal variables squared). Once we get the p-value, as explained in the _Getting started with statistical hypothesis testing – a simple z-test_ recipe, we can reject or accept the null hypothesis of independence. Then, we can conclude (or not) that there exists a significant correlation between the variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpTsMpecwMNq",
        "colab_type": "text"
      },
      "source": [
        "# There's more..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBhbNBqqwT-j",
        "colab_type": "text"
      },
      "source": [
        "There are many other sorts of chi-squared tests, that is, tests where the test statistic follows a chi-squared distribution. These tests are widely used for testing the goodness-of-fit of a distribution, or testing the independence of variables. More information can be found in the following pages:\n",
        "\n",
        "+ Chi2 test in SciPy documentation available at http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html\n",
        "+ Contingency table introduced at https://en.wikipedia.org/wiki/Contingency_table\n",
        "+ Chi-squared test introduced at https://en.wikipedia.org/wiki/Pearson's_chi-squared_test"
      ]
    }
  ]
}